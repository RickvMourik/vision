{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.load_data import load_train, load_test, load_example\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image recognition met een \"normaal\" neuraal netwerk. \n",
    "\n",
    "Neurale netwerken zijn ontzettend sterke wiskundige modellen. Een “normaal” neuraal netwerk heeft echter wel wat limieten. Om een aantal van deze limieten te doorbreken, kan je een convolutional neuraal netwerk gebruiken. \n",
    "\n",
    "We beginnen met het exploreren van de limieten van normale neurale netwerken, dit doen we doormiddel van de MNIST-dataset.\n",
    "\n",
    "MNIST is een dataset van 70.000 handgeschreven cijfers (0..9), opgesplitst in 60.000 training images en 10.000 testing images. We hebben al functies geschreven waarmee je de data kan inladen, zie de cell hieronder.\n",
    "\n",
    "Deze data is steeds opgedeeld in 2 stukken: train en labels.\n",
    "\n",
    "train is een (numpy) array met alle inputafbeeldingen erin.\n",
    "labels is een (numpy) array met voor elke inputafbeelding de werkelijke waarde.\n",
    "\n",
    "Als train[5] een afbeelding van een 4 is, dan geldt dus: labels[5] == 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 4\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Laad de trainingsdata en labels\n",
    "train_data, train_labels = load_train()\n",
    "# De kleurwaarden in de afbeelding zijn nu 0 tot 255, we zetten deze om naar -0.5 tot 0.5\n",
    "train_data = (train_data / 255) - 0.5\n",
    "\n",
    "\n",
    "plt.imshow(train_data[2])\n",
    "plt.title(f\"{train_labels[2]}\")\n",
    "print(f\"Label: {train_labels[2]}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Data formatting\n",
    "Voordat we een neuraal netwerk kunnen trainen op de MNIST-data, moet deze verwerkt worden.\n",
    "\n",
    "De input data zijn op het moment grijsafbeeldingen, en dus 2-dimensionaal (x,y).\n",
    "Alleen elke input van dit neuraal netwerk moet 1-dimensionaal zijn. Probeer nu zelf train_data om te zetten naar een\n",
    "correct format. De labels hebben wij zelf al voor je omgezet naar het juiste formaat.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = to_categorical(train_labels, 10)\n",
    "\n",
    "\n",
    "train_data = train_data.reshape([60000,868])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 868)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handig om te weten: Image recognition geeft in het algemeen ontzettend grote input vectors.\n",
    "MNIST is in grayscale, maar veel plaatjes zijn dat niet. Als je ook nog kleur wil meegeven,\n",
    "zou de input vector nog drie keer zo groot zijn.\n",
    "\n",
    "### Bouwen van een NN\n",
    "\n",
    "De volgende stap is om een neuraal netwerk te bouwen.\n",
    "Maak zelf de eerste Dense layer af, kijk vervolgens ook naar hoeveel hidden layers je toevoegt.\n",
    "Bij image recognition is de activation function ook erg belangrijk.\n",
    "Denk goed na over welke je gebruikt. De laatste layer geven wij alvast aan je.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 32)                27808     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 28,138\n",
      "Trainable params: 28,138\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# input_dim moet gelijk zijn aan de lengte van 1 input\n",
    "model.add(Dense(32, input_dim=868)) # FIXME\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hieruit kan je al direct het eerste probleem van normale neurale netwerken inzien; er is een gigantische hoeveelheid trainbare parameters. \n",
    "\n",
    "Iedere node moet verbonden zijn aan iedere node. Bij image recognition is de input vector gigantisch, dit houdt dus ook in dat er een gigantische hoeveelheid weights zijn waarmee jouw neuraal netwerk rekening moet houden. \n",
    "\n",
    "Dit maakt het trainen best zwaar en langzaam.\n",
    "\n",
    "Het klaarmaken van een neural network in Keras heeft de volgende stappen:\n",
    "- Aangeven van de layers, dit hebben we net gedaan\n",
    "- Compilen, het model word nu geconfigureerd om hem klaar te maken voor trainen\n",
    "- Fit, het model word nu \"getraind\" op data die je meegeeft. Hieraan geef je zowel data als labels mee\n",
    "- Evaluate; Controller het model om te kijken of het accuraat is. Geef hieraan data en labels mee, maar zorg dat deze data niet ook in je trainingsdata zit\n",
    "- Predict; Geef inputdata mee, waarvan je het label nog niet kent. het NN probeert het label nu te bedenken.\n",
    "Ga nu door met het trainen van dit neuraal netwerk. Ook de `.compile()` hebben wij al aan je geven, ook hier mag je mee spelen.\n",
    "\n",
    "Probeer jouw neuraal netwerk zo accuraat mogelijk te maken. (doe dit door te kijken naar de resultaten van de `.fit()`; `.evaluate()` komt later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In AI is het aantal epochs het aantal keer dat je over de volledige dataset heen gaat om te trainen.\n",
    "\n",
    "Experimenteer met deze waarde om te kijken wat voor invloed deze heeft."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1875/1875 [==============================] - 1s 536us/step - loss: 0.4361 - accuracy: 0.8697\n",
      "Epoch 2/150\n",
      "1875/1875 [==============================] - 1s 543us/step - loss: 0.3395 - accuracy: 0.9021\n",
      "Epoch 3/150\n",
      "1875/1875 [==============================] - 1s 538us/step - loss: 0.3236 - accuracy: 0.9081\n",
      "Epoch 4/150\n",
      "1875/1875 [==============================] - 1s 535us/step - loss: 0.3146 - accuracy: 0.9102\n",
      "Epoch 5/150\n",
      "1875/1875 [==============================] - 1s 547us/step - loss: 0.3093 - accuracy: 0.9118\n",
      "Epoch 6/150\n",
      "1875/1875 [==============================] - 1s 542us/step - loss: 0.3040 - accuracy: 0.9135\n",
      "Epoch 7/150\n",
      "1875/1875 [==============================] - 1s 520us/step - loss: 0.3010 - accuracy: 0.9136\n",
      "Epoch 8/150\n",
      "1875/1875 [==============================] - 1s 524us/step - loss: 0.2970 - accuracy: 0.9163\n",
      "Epoch 9/150\n",
      "1875/1875 [==============================] - 1s 529us/step - loss: 0.2951 - accuracy: 0.9166\n",
      "Epoch 10/150\n",
      "1875/1875 [==============================] - 1s 529us/step - loss: 0.2919 - accuracy: 0.9177\n",
      "Epoch 11/150\n",
      "1875/1875 [==============================] - 1s 527us/step - loss: 0.2893 - accuracy: 0.9174\n",
      "Epoch 12/150\n",
      "1875/1875 [==============================] - 1s 537us/step - loss: 0.2886 - accuracy: 0.9183\n",
      "Epoch 13/150\n",
      "1875/1875 [==============================] - 1s 525us/step - loss: 0.2878 - accuracy: 0.9193\n",
      "Epoch 14/150\n",
      "1875/1875 [==============================] - 1s 525us/step - loss: 0.2858 - accuracy: 0.9200\n",
      "Epoch 15/150\n",
      "1875/1875 [==============================] - 1s 520us/step - loss: 0.2838 - accuracy: 0.9196\n",
      "Epoch 16/150\n",
      "1875/1875 [==============================] - 1s 526us/step - loss: 0.2829 - accuracy: 0.9199\n",
      "Epoch 17/150\n",
      "1875/1875 [==============================] - 1s 522us/step - loss: 0.2818 - accuracy: 0.9213\n",
      "Epoch 18/150\n",
      "1875/1875 [==============================] - 1s 518us/step - loss: 0.2812 - accuracy: 0.9210\n",
      "Epoch 19/150\n",
      "1875/1875 [==============================] - 1s 547us/step - loss: 0.2792 - accuracy: 0.9219\n",
      "Epoch 20/150\n",
      "1875/1875 [==============================] - 1s 522us/step - loss: 0.2790 - accuracy: 0.9214\n",
      "Epoch 21/150\n",
      "1875/1875 [==============================] - 1s 523us/step - loss: 0.2785 - accuracy: 0.9221\n",
      "Epoch 22/150\n",
      "1875/1875 [==============================] - 1s 522us/step - loss: 0.2776 - accuracy: 0.9220\n",
      "Epoch 23/150\n",
      "1875/1875 [==============================] - 1s 516us/step - loss: 0.2757 - accuracy: 0.9219\n",
      "Epoch 24/150\n",
      "1875/1875 [==============================] - 1s 524us/step - loss: 0.2764 - accuracy: 0.9226\n",
      "Epoch 25/150\n",
      "1875/1875 [==============================] - 1s 522us/step - loss: 0.2746 - accuracy: 0.9232\n",
      "Epoch 26/150\n",
      "1875/1875 [==============================] - 1s 524us/step - loss: 0.2737 - accuracy: 0.9229\n",
      "Epoch 27/150\n",
      "1875/1875 [==============================] - 1s 520us/step - loss: 0.2732 - accuracy: 0.9228\n",
      "Epoch 28/150\n",
      "1875/1875 [==============================] - 1s 521us/step - loss: 0.2740 - accuracy: 0.9230\n",
      "Epoch 29/150\n",
      "1875/1875 [==============================] - 1s 523us/step - loss: 0.2721 - accuracy: 0.9234\n",
      "Epoch 30/150\n",
      "1875/1875 [==============================] - 1s 521us/step - loss: 0.2720 - accuracy: 0.9234\n",
      "Epoch 31/150\n",
      "1875/1875 [==============================] - 1s 524us/step - loss: 0.2706 - accuracy: 0.9238\n",
      "Epoch 32/150\n",
      "1875/1875 [==============================] - 1s 585us/step - loss: 0.2707 - accuracy: 0.9239\n",
      "Epoch 33/150\n",
      "1875/1875 [==============================] - 1s 518us/step - loss: 0.2703 - accuracy: 0.9248\n",
      "Epoch 34/150\n",
      "1875/1875 [==============================] - 1s 521us/step - loss: 0.2694 - accuracy: 0.9244\n",
      "Epoch 35/150\n",
      "1875/1875 [==============================] - 1s 522us/step - loss: 0.2694 - accuracy: 0.9238\n",
      "Epoch 36/150\n",
      "1875/1875 [==============================] - 1s 520us/step - loss: 0.2694 - accuracy: 0.9249\n",
      "Epoch 37/150\n",
      "1875/1875 [==============================] - 1s 516us/step - loss: 0.2690 - accuracy: 0.9242\n",
      "Epoch 38/150\n",
      "1875/1875 [==============================] - 1s 520us/step - loss: 0.2686 - accuracy: 0.9255\n",
      "Epoch 39/150\n",
      "1875/1875 [==============================] - 1s 525us/step - loss: 0.2674 - accuracy: 0.9252\n",
      "Epoch 40/150\n",
      "1875/1875 [==============================] - 1s 519us/step - loss: 0.2673 - accuracy: 0.9263\n",
      "Epoch 41/150\n",
      "1875/1875 [==============================] - 1s 520us/step - loss: 0.2670 - accuracy: 0.9257\n",
      "Epoch 42/150\n",
      "1875/1875 [==============================] - 1s 520us/step - loss: 0.2666 - accuracy: 0.9258\n",
      "Epoch 43/150\n",
      "1875/1875 [==============================] - 1s 522us/step - loss: 0.2664 - accuracy: 0.9252\n",
      "Epoch 44/150\n",
      "1875/1875 [==============================] - 1s 522us/step - loss: 0.2664 - accuracy: 0.9251\n",
      "Epoch 45/150\n",
      "1875/1875 [==============================] - 1s 521us/step - loss: 0.2661 - accuracy: 0.9253\n",
      "Epoch 46/150\n",
      "1875/1875 [==============================] - 1s 518us/step - loss: 0.2643 - accuracy: 0.9260\n",
      "Epoch 47/150\n",
      "1875/1875 [==============================] - 1s 521us/step - loss: 0.2655 - accuracy: 0.9257\n",
      "Epoch 48/150\n",
      "1875/1875 [==============================] - 1s 523us/step - loss: 0.2651 - accuracy: 0.9253\n",
      "Epoch 49/150\n",
      "1875/1875 [==============================] - 1s 523us/step - loss: 0.2654 - accuracy: 0.9258\n",
      "Epoch 50/150\n",
      "1875/1875 [==============================] - 1s 519us/step - loss: 0.2653 - accuracy: 0.9255\n",
      "Epoch 51/150\n",
      "1875/1875 [==============================] - 1s 523us/step - loss: 0.2633 - accuracy: 0.9262\n",
      "Epoch 52/150\n",
      "1875/1875 [==============================] - 1s 520us/step - loss: 0.2638 - accuracy: 0.9261\n",
      "Epoch 53/150\n",
      "1875/1875 [==============================] - 1s 523us/step - loss: 0.2632 - accuracy: 0.9267\n",
      "Epoch 54/150\n",
      "1875/1875 [==============================] - 1s 538us/step - loss: 0.2631 - accuracy: 0.92710s - loss: 0.2632 - accuracy: \n",
      "Epoch 55/150\n",
      "1875/1875 [==============================] - 1s 522us/step - loss: 0.2633 - accuracy: 0.92630s - loss: 0.2572 - \n",
      "Epoch 56/150\n",
      "1875/1875 [==============================] - 1s 560us/step - loss: 0.2629 - accuracy: 0.9267\n",
      "Epoch 57/150\n",
      "1875/1875 [==============================] - 1s 576us/step - loss: 0.2624 - accuracy: 0.9266\n",
      "Epoch 58/150\n",
      "1875/1875 [==============================] - 1s 564us/step - loss: 0.2639 - accuracy: 0.9262\n",
      "Epoch 59/150\n",
      "1875/1875 [==============================] - 1s 585us/step - loss: 0.2624 - accuracy: 0.92710s - loss: 0.2630 - accuracy: 0.92\n",
      "Epoch 60/150\n",
      "1875/1875 [==============================] - 1s 587us/step - loss: 0.2620 - accuracy: 0.9271\n",
      "Epoch 61/150\n",
      "1875/1875 [==============================] - 1s 594us/step - loss: 0.2619 - accuracy: 0.9267\n",
      "Epoch 62/150\n",
      "1875/1875 [==============================] - 1s 540us/step - loss: 0.2620 - accuracy: 0.9267\n",
      "Epoch 63/150\n",
      "1875/1875 [==============================] - 1s 539us/step - loss: 0.2614 - accuracy: 0.9272\n",
      "Epoch 64/150\n",
      "1875/1875 [==============================] - 1s 528us/step - loss: 0.2613 - accuracy: 0.9274\n",
      "Epoch 65/150\n",
      "1875/1875 [==============================] - 1s 522us/step - loss: 0.2606 - accuracy: 0.9263\n",
      "Epoch 66/150\n",
      "1875/1875 [==============================] - 1s 533us/step - loss: 0.2619 - accuracy: 0.9277\n",
      "Epoch 67/150\n",
      "1875/1875 [==============================] - 1s 543us/step - loss: 0.2599 - accuracy: 0.9268\n",
      "Epoch 68/150\n",
      "1875/1875 [==============================] - 1s 544us/step - loss: 0.2604 - accuracy: 0.9276\n",
      "Epoch 69/150\n",
      "1875/1875 [==============================] - 1s 534us/step - loss: 0.2607 - accuracy: 0.9269\n",
      "Epoch 70/150\n",
      "1875/1875 [==============================] - 1s 524us/step - loss: 0.2604 - accuracy: 0.9261\n",
      "Epoch 71/150\n",
      "1875/1875 [==============================] - 1s 523us/step - loss: 0.2599 - accuracy: 0.9283\n",
      "Epoch 72/150\n",
      "1875/1875 [==============================] - 1s 524us/step - loss: 0.2609 - accuracy: 0.9273\n",
      "Epoch 73/150\n",
      "1875/1875 [==============================] - 1s 515us/step - loss: 0.2591 - accuracy: 0.92770s - loss: 0.2595 - accuracy: 0.92\n",
      "Epoch 74/150\n",
      "1875/1875 [==============================] - 1s 534us/step - loss: 0.2600 - accuracy: 0.9275\n",
      "Epoch 75/150\n",
      "1875/1875 [==============================] - 1s 541us/step - loss: 0.2590 - accuracy: 0.9277\n",
      "Epoch 76/150\n",
      "1875/1875 [==============================] - 1s 524us/step - loss: 0.2590 - accuracy: 0.9274\n",
      "Epoch 77/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 1s 524us/step - loss: 0.2590 - accuracy: 0.9273\n",
      "Epoch 78/150\n",
      "1875/1875 [==============================] - 1s 531us/step - loss: 0.2587 - accuracy: 0.9285\n",
      "Epoch 79/150\n",
      "1875/1875 [==============================] - 1s 526us/step - loss: 0.2591 - accuracy: 0.9285\n",
      "Epoch 80/150\n",
      "1875/1875 [==============================] - 1s 525us/step - loss: 0.2593 - accuracy: 0.9271\n",
      "Epoch 81/150\n",
      "1875/1875 [==============================] - 1s 526us/step - loss: 0.2592 - accuracy: 0.9270\n",
      "Epoch 82/150\n",
      "1875/1875 [==============================] - 1s 530us/step - loss: 0.2591 - accuracy: 0.9269\n",
      "Epoch 83/150\n",
      "1875/1875 [==============================] - 1s 527us/step - loss: 0.2584 - accuracy: 0.9270\n",
      "Epoch 84/150\n",
      "1875/1875 [==============================] - 1s 530us/step - loss: 0.2587 - accuracy: 0.9280\n",
      "Epoch 85/150\n",
      "1875/1875 [==============================] - 1s 530us/step - loss: 0.2582 - accuracy: 0.9278\n",
      "Epoch 86/150\n",
      "1875/1875 [==============================] - 1s 528us/step - loss: 0.2585 - accuracy: 0.92780s - loss: 0.2561 - ac\n",
      "Epoch 87/150\n",
      "1875/1875 [==============================] - 1s 536us/step - loss: 0.2583 - accuracy: 0.9284\n",
      "Epoch 88/150\n",
      "1875/1875 [==============================] - 1s 538us/step - loss: 0.2579 - accuracy: 0.9285\n",
      "Epoch 89/150\n",
      "1875/1875 [==============================] - 1s 551us/step - loss: 0.2580 - accuracy: 0.9284\n",
      "Epoch 90/150\n",
      "1875/1875 [==============================] - 1s 530us/step - loss: 0.2575 - accuracy: 0.9278\n",
      "Epoch 91/150\n",
      "1875/1875 [==============================] - 1s 539us/step - loss: 0.2576 - accuracy: 0.92800s - loss: 0.2579 - accu\n",
      "Epoch 92/150\n",
      "1875/1875 [==============================] - 1s 546us/step - loss: 0.2575 - accuracy: 0.9276\n",
      "Epoch 93/150\n",
      "1875/1875 [==============================] - 1s 552us/step - loss: 0.2579 - accuracy: 0.9273\n",
      "Epoch 94/150\n",
      "1875/1875 [==============================] - 1s 530us/step - loss: 0.2575 - accuracy: 0.9270\n",
      "Epoch 95/150\n",
      "1875/1875 [==============================] - 1s 538us/step - loss: 0.2570 - accuracy: 0.9283\n",
      "Epoch 96/150\n",
      "1875/1875 [==============================] - 1s 544us/step - loss: 0.2575 - accuracy: 0.9273\n",
      "Epoch 97/150\n",
      "1875/1875 [==============================] - 1s 537us/step - loss: 0.2569 - accuracy: 0.9282\n",
      "Epoch 98/150\n",
      "1875/1875 [==============================] - 1s 546us/step - loss: 0.2571 - accuracy: 0.92810s - l\n",
      "Epoch 99/150\n",
      "1875/1875 [==============================] - 1s 541us/step - loss: 0.2560 - accuracy: 0.9285\n",
      "Epoch 100/150\n",
      "1875/1875 [==============================] - 1s 557us/step - loss: 0.2557 - accuracy: 0.9284\n",
      "Epoch 101/150\n",
      "1875/1875 [==============================] - 1s 557us/step - loss: 0.2575 - accuracy: 0.9276\n",
      "Epoch 102/150\n",
      "1875/1875 [==============================] - 1s 577us/step - loss: 0.2560 - accuracy: 0.9280\n",
      "Epoch 103/150\n",
      "1875/1875 [==============================] - 1s 551us/step - loss: 0.2561 - accuracy: 0.9285\n",
      "Epoch 104/150\n",
      "1875/1875 [==============================] - 1s 538us/step - loss: 0.2562 - accuracy: 0.9283\n",
      "Epoch 105/150\n",
      "1875/1875 [==============================] - 1s 550us/step - loss: 0.2575 - accuracy: 0.9266\n",
      "Epoch 106/150\n",
      "1875/1875 [==============================] - 1s 516us/step - loss: 0.2563 - accuracy: 0.9287\n",
      "Epoch 107/150\n",
      "1875/1875 [==============================] - 1s 518us/step - loss: 0.2556 - accuracy: 0.9294\n",
      "Epoch 108/150\n",
      "1875/1875 [==============================] - 1s 522us/step - loss: 0.2557 - accuracy: 0.9281\n",
      "Epoch 109/150\n",
      "1875/1875 [==============================] - 1s 534us/step - loss: 0.2553 - accuracy: 0.9285\n",
      "Epoch 110/150\n",
      "1875/1875 [==============================] - 1s 516us/step - loss: 0.2556 - accuracy: 0.9290\n",
      "Epoch 111/150\n",
      "1875/1875 [==============================] - 1s 518us/step - loss: 0.2556 - accuracy: 0.9281\n",
      "Epoch 112/150\n",
      "1875/1875 [==============================] - 1s 518us/step - loss: 0.2556 - accuracy: 0.9284\n",
      "Epoch 113/150\n",
      "1875/1875 [==============================] - 1s 518us/step - loss: 0.2553 - accuracy: 0.92830s - los\n",
      "Epoch 114/150\n",
      "1875/1875 [==============================] - 1s 519us/step - loss: 0.2562 - accuracy: 0.9286\n",
      "Epoch 115/150\n",
      "1875/1875 [==============================] - 1s 517us/step - loss: 0.2555 - accuracy: 0.9274\n",
      "Epoch 116/150\n",
      "1875/1875 [==============================] - 1s 515us/step - loss: 0.2547 - accuracy: 0.9286\n",
      "Epoch 117/150\n",
      "1875/1875 [==============================] - 1s 520us/step - loss: 0.2544 - accuracy: 0.9285\n",
      "Epoch 118/150\n",
      "1875/1875 [==============================] - 1s 520us/step - loss: 0.2555 - accuracy: 0.9293\n",
      "Epoch 119/150\n",
      "1875/1875 [==============================] - 1s 517us/step - loss: 0.2547 - accuracy: 0.9290\n",
      "Epoch 120/150\n",
      "1875/1875 [==============================] - 1s 520us/step - loss: 0.2545 - accuracy: 0.9288\n",
      "Epoch 121/150\n",
      "1875/1875 [==============================] - 1s 516us/step - loss: 0.2551 - accuracy: 0.9287\n",
      "Epoch 122/150\n",
      "1875/1875 [==============================] - 1s 515us/step - loss: 0.2543 - accuracy: 0.9282\n",
      "Epoch 123/150\n",
      "1875/1875 [==============================] - 1s 519us/step - loss: 0.2554 - accuracy: 0.9283\n",
      "Epoch 124/150\n",
      "1875/1875 [==============================] - 1s 514us/step - loss: 0.2535 - accuracy: 0.9291\n",
      "Epoch 125/150\n",
      "1875/1875 [==============================] - 1s 515us/step - loss: 0.2543 - accuracy: 0.9281\n",
      "Epoch 126/150\n",
      "1875/1875 [==============================] - 1s 515us/step - loss: 0.2538 - accuracy: 0.9283\n",
      "Epoch 127/150\n",
      "1875/1875 [==============================] - 1s 516us/step - loss: 0.2537 - accuracy: 0.9290\n",
      "Epoch 128/150\n",
      "1875/1875 [==============================] - 1s 525us/step - loss: 0.2543 - accuracy: 0.9287\n",
      "Epoch 129/150\n",
      "1875/1875 [==============================] - 1s 514us/step - loss: 0.2541 - accuracy: 0.9282\n",
      "Epoch 130/150\n",
      "1875/1875 [==============================] - 1s 514us/step - loss: 0.2541 - accuracy: 0.9298\n",
      "Epoch 131/150\n",
      "1875/1875 [==============================] - 1s 523us/step - loss: 0.2536 - accuracy: 0.9288\n",
      "Epoch 132/150\n",
      "1875/1875 [==============================] - 1s 592us/step - loss: 0.2536 - accuracy: 0.9286\n",
      "Epoch 133/150\n",
      "1875/1875 [==============================] - 1s 543us/step - loss: 0.2536 - accuracy: 0.9296\n",
      "Epoch 134/150\n",
      "1875/1875 [==============================] - 1s 531us/step - loss: 0.2543 - accuracy: 0.9290\n",
      "Epoch 135/150\n",
      "1875/1875 [==============================] - 1s 525us/step - loss: 0.2534 - accuracy: 0.9294\n",
      "Epoch 136/150\n",
      "1875/1875 [==============================] - 1s 527us/step - loss: 0.2532 - accuracy: 0.9298\n",
      "Epoch 137/150\n",
      "1875/1875 [==============================] - 1s 528us/step - loss: 0.2533 - accuracy: 0.9285\n",
      "Epoch 138/150\n",
      "1875/1875 [==============================] - 1s 532us/step - loss: 0.2522 - accuracy: 0.9287\n",
      "Epoch 139/150\n",
      "1875/1875 [==============================] - 1s 533us/step - loss: 0.2531 - accuracy: 0.9289\n",
      "Epoch 140/150\n",
      "1875/1875 [==============================] - 1s 532us/step - loss: 0.2533 - accuracy: 0.9292\n",
      "Epoch 141/150\n",
      "1875/1875 [==============================] - 1s 540us/step - loss: 0.2531 - accuracy: 0.9285\n",
      "Epoch 142/150\n",
      "1875/1875 [==============================] - 1s 547us/step - loss: 0.2531 - accuracy: 0.9285\n",
      "Epoch 143/150\n",
      "1875/1875 [==============================] - 1s 541us/step - loss: 0.2521 - accuracy: 0.9294\n",
      "Epoch 144/150\n",
      "1875/1875 [==============================] - 1s 525us/step - loss: 0.2532 - accuracy: 0.9298\n",
      "Epoch 145/150\n",
      "1875/1875 [==============================] - 1s 530us/step - loss: 0.2524 - accuracy: 0.9297\n",
      "Epoch 146/150\n",
      "1875/1875 [==============================] - 1s 527us/step - loss: 0.2535 - accuracy: 0.9294\n",
      "Epoch 147/150\n",
      "1875/1875 [==============================] - 1s 539us/step - loss: 0.2522 - accuracy: 0.9294\n",
      "Epoch 148/150\n",
      "1875/1875 [==============================] - 1s 529us/step - loss: 0.2526 - accuracy: 0.9298\n",
      "Epoch 149/150\n",
      "1875/1875 [==============================] - 1s 523us/step - loss: 0.2511 - accuracy: 0.9297\n",
      "Epoch 150/150\n",
      "1875/1875 [==============================] - 1s 527us/step - loss: 0.2518 - accuracy: 0.92830s - loss: 0.2478 - accu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e3954a5b20>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data, train_labels, epochs=150) # FIXME set epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Het evalueren van het neurale netwerk\n",
    "Ook hier moet de data eerst nog omgevormd worden, gebruik hiervoor dezelfde code als bij de training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data, test_labels = load_test()\n",
    "\n",
    "test_data = test_data/255.0 - 0.5\n",
    "\n",
    "\n",
    "test_data = test_data.reshape([10000,868])\n",
    "test_labels = to_categorical(test_labels, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/313 [..............................] - ETA: 0s - loss: 3.9827 - accuracy: 0.4688WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "313/313 [==============================] - 0s 393us/step - loss: 4.4849 - accuracy: 0.4384\n",
      "loss: 4.484933376312256, accuracy: 0.438400000333786 van de 1.0\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(test_data, test_labels)\n",
    "\n",
    "print(f\"loss: {result[0]}, accuracy: {result[1]} van de 1.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Huh?\n",
    "Hoogstwaarschijnlijk scoort jouw neuraal netwerk nu ontzettend slecht. Om een limiet van neurale netwerken zichtbaar te maken, hebben we een klein beetje valsgespeeld. We hebben wat padding toegevoegd; een aantal pixels aan de linkerkant bij de testing data en een aantal pixels aan de rechterkant bij de training data. Zie de plots hieronder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "(example_r, example_l), label = load_example()\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "axs[0].imshow(example_r)\n",
    "axs[0].set_title(\"Padding on right side (Like training)\")\n",
    "\n",
    "axs[1].imshow(example_l)\n",
    "axs[1].set_title(\"Padding on left side (Like testing)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De standaardwaarde voor de padding is 3(!!) pixels, dit heeft een gigantisch effect op de accuratesse.\n",
    "Formatteer nog één keer de data (`examples`), en kijk wat er uit de `.predict()` komt.\n",
    "\n",
    "Er bestaat een kans dat jouw model hier de goede voorspelt, probeer dan bij `load_example()` het argument `index` te veranderen naar een ander getal. Waarschijnlijk zal het dan wel fout voorspellen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = np.array([example_r, example_l])\n",
    "\n",
    "examples = examples.reshape([2,868])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Waarom?\n",
    "\n",
    "De voorspellingen van een gewoon neuraal netwerk zijn ruimtelijk bepaald, het herkent patronen op specifieke plekken. Het verplaatsen van deze patronen met maar een paar pixels kan al genoeg zijn om het onmogelijk te maken voor een gewoon neuraal netwerk om deze te herkennen. \n",
    "\n",
    "Een neuraal netwerk getraind op het herkennen van honden en fietsen, zou heel makkelijk het volgende gedrag kunnen laten zien:\n",
    "\n",
    "\n",
    "\n",
    "![Right!](src/top-left-dog.png)\n",
    "\n",
    "![Wrong!](src/top-left-bike.png)\n",
    "\n",
    "\n",
    "Speel is een beetje rond met de padding, kijk is hoeveel impact 4 pixels heeft, zelfs 1 pixel kan al een grote impact hebben!\n",
    "\n",
    "Wij raden aan om alleen de horizontale padding te veranderen, het format van het padding argument in `load_train`, `load_test`, en `load_example` is dan: `((0, 0), (0, 0), (left sided padding, right sided padding))`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Aldewereld, H. & van der Bijl, B. & Bunk, J. (2017, oktober). Applied Artificial Intelligence. Geraadpleegd op 13 maart 2020, van https://canvas.hu.nl/courses/7569/files/694738/download?wrap=1\n",
    "\n",
    "- Chollet, F. (2019, November 6). Getting started with the Keras Sequential model. Geraadpleegd op 13 maart 2020, van keras.io: https://keras.io/getting-started/sequential-model-guide/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
